"use strict";(self.webpackChunkcookbook=self.webpackChunkcookbook||[]).push([[130],{14446:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>g,frontMatter:()=>r,metadata:()=>i,toc:()=>l});var o=t(74848),a=t(28453);const r={slug:"huggingface",authors:["msrivastav13"],tags:["huggingface","heroku","llm-open-connector"],date:new Date("2024-09-12T00:00:00.000Z")},s="LLM Open Connector + Hugging Face",i={permalink:"/einstein-platform/huggingface",source:"@site/cookbook/llm-open-connector-huggingface.mdx",title:"LLM Open Connector + Hugging Face",description:"Learn how to implement Salesforce's LLM Open Connector with the Hugging Face Serverless Inference API for LLM models that support Chat Completion. We also cover how to implement and deploy the connector as a Node.js app on Heroku.",date:"2024-09-12T00:00:00.000Z",tags:[{inline:!1,label:"huggingface",permalink:"/einstein-platform/tags/huggingface"},{inline:!1,label:"heroku",permalink:"/einstein-platform/tags/heroku"},{inline:!1,label:"llm-open-connector",permalink:"/einstein-platform/tags/llm-open-connector"}],readingTime:7.48,hasTruncateMarker:!0,authors:[{name:"Mohith",title:"Developer Advocate @ Salesforce",url:"https://github.com/msrivastav13",page:{permalink:"/einstein-platform/authors/msrivastav-13"},socials:{github:"https://github.com/msrivastav13"},imageURL:"https://github.com/msrivastav13.png",key:"msrivastav13"}],frontMatter:{slug:"huggingface",authors:["msrivastav13"],tags:["huggingface","heroku","llm-open-connector"],date:"2024-09-12T00:00:00.000Z"},unlisted:!1,prevItem:{title:"Introducing the LLM Open Connector",permalink:"/einstein-platform/open-connector"},nextItem:{title:"LLM Open Connector + AWS",permalink:"/einstein-platform/aws"}},c={authorsImageUrls:[void 0]},l=[];function p(e){const n={a:"a",p:"p",...(0,a.R)(),...e.components};return(0,o.jsxs)(n.p,{children:["Learn how to implement Salesforce's ",(0,o.jsx)(n.a,{href:"/docs/apis/llm-open-connector/",children:"LLM Open Connector"})," with the Hugging Face ",(0,o.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/index",children:"Serverless Inference API"})," for LLM models that support ",(0,o.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/en/tasks/chat-completion",children:"Chat Completion"}),". We also cover how to implement and deploy the connector as a Node.js app on Heroku."]})}function g(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var o=t(96540);const a={},r=o.createContext(a);function s(e){const n=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);